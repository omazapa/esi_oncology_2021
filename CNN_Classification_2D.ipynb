{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590ddf59",
   "metadata": {},
   "source": [
    "<img style=\"width:20%;float: left; margin-right: 10px;\" src=\"https://upload.wikimedia.org/wikipedia/en/a/ae/CERN_logo.svg\"/>\n",
    "\n",
    "\n",
    "\n",
    "#    2D images classification using Machine Leaning for brain tumors\n",
    "\n",
    "## Introduction\n",
    "Brain tumors are considered by the medical community, an aggressive and difficult to treat disease that affects adults and children.\n",
    "\n",
    "The most common primary brain tumors are Gliomas, followed by Meningiomas and Pituitary.\n",
    "\n",
    "Gliomas are the most common type of adult brain tumor, It is about 78 percent of malignant brain tumors according to the American Association of Neurological Surgeons.<a href=\"#1\">[1]</a>\n",
    "\n",
    "In this tutorial we are going to classify 2D images with machine learning, for brain tumor such as **meningioma**, **glioma** and **pituitary**, respect people with no tumors.\n",
    "\n",
    "As mentioned in the preprocessing notebook, we are using like ilustrative example a public dataset, taken from \n",
    "kaggle <a href=\"#2\">[2]</a>, this is a 2D MRI dataset.\n",
    "\n",
    "\n",
    "## About ML for Brain Tumor Classification\n",
    "\n",
    "Brain tumor classification is complex task, it requies sophistcate machine learning and math models using the newest in the state of the art for image processing like Convolutional Neural Networks <a href=\"#3\">[3]</a>.\n",
    "It also requires elaborated techniques to preprocess the images, such as skull stripping <a href=\"#4\">[4]</a>, advanced tools for data normalization such as Ants <a href=\"#5\">[5]</a>, tools for image transformation such as\n",
    "scikit-image <a href=\"#6\">[6]</a> or open computer vision library (open-cv) <a href=\"#7\">[7]</a>\n",
    "\n",
    "This tutorial is done using Tensorflow with Keras <a href=\"#8\">[8]</a> and due the limited resources will a binary classifier using 64x64 pixels 2D images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59460cee",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Let's get started!\n",
    "\n",
    "The first step is to import the required modules. those modules are to handle numeric arrays, plotting, create the machine learning model and compute some statistics over the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam #http://arxiv.org/abs/1412.6980\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout,BatchNormalization,Activation,SpatialDropout2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61772e0b",
   "metadata": {},
   "source": [
    "# Defining and Select the categories\n",
    "\n",
    "The second step is to defined the categories for our problem, in our case is an array of four labels for meningioma, glioma, pituitary tumors and not tumor.\n",
    "\n",
    "We have to select two of those categories to perform the binary classification, initially we will take no tumor and glioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b645cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['meningioma_tumor', 'glioma_tumor', 'pituitary_tumor', 'no_tumor']\n",
    "categories_selected = [\"no_tumor\",\"glioma_tumor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ff75e",
   "metadata": {},
   "source": [
    "# Utility function to plot a confisuion matrix\n",
    "\n",
    "Confusion matrix is a table layout that allows to visualize the performance of the algorithm.<a href=\"#9\">[9]</a>\n",
    "\n",
    "This allows see :\n",
    "* TP: True postive \n",
    "* TN: True negative\n",
    "* FP: False positive\n",
    "* FN: False negative\n",
    "\n",
    "\n",
    "We took this code  snippet from kaggle <a href=\"#10\">[10]</a> to produce a nice plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca206ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ff84e",
   "metadata": {},
   "source": [
    "# Utility funtion to load the dataset\n",
    "\n",
    "This function allows to load the datasets for training and testing.\n",
    "\n",
    "We are taking in this function the data already preprocessed in the other preprocessing notebook.\n",
    "\n",
    "this function returns two variables:\n",
    "* x_(train/test): this is a tensor with images\n",
    "* y_(train/test): array with zeros and ones  for labels. (ex: 0 = no tumor and 1 = glioma)\n",
    "\n",
    "to load the proper set of data we have to pass two parameters to the funtion:\n",
    "* dataset:  is a string with the value \"training\" or \"testing\"  to know which set are we loaing.\n",
    "* _categories: two strings in an array to know which categories are we using (ex: [\"no_tumor\",\"glioma_tumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset,_categories):\n",
    "    data = []\n",
    "    labels = []\n",
    "    path = \"\"\n",
    "    \n",
    "    if dataset != \"training\" or dataset == \"testing\":\n",
    "        print(f\"Error: invalid dataset type, options are 'training' or 'testing'\")\n",
    "        return\n",
    "    \n",
    "    if dataset == \"training\":\n",
    "        print(\"loading preprocessed training dataset\")\n",
    "        path = \"preprocessed/Training\"\n",
    "        \n",
    "    if dataset == \"testing\":\n",
    "        print(\"loading preprocessed testing dataset\")\n",
    "        path = \"preprocessed/Testing\"\n",
    "        \n",
    "    if len(_categories) != 2:\n",
    "        print(\"Error: please select two categories, this is for a binary classifier\")\n",
    "        return\n",
    "    \n",
    "    for category in _categories:\n",
    "        if category not in categories:\n",
    "            print(f\"Error: invalid category, options are {categories}\")\n",
    "            return \n",
    "        \n",
    "    for category in _categories:\n",
    "        label = _categories.index(category)\n",
    "        cat_path=f\"{path}/{category}\"\n",
    "        print(f\"loading category {category} from path {cat_path}\")\n",
    "        imgs_files = glob.glob(f\"{cat_path}/*\")\n",
    "        for img in imgs_files:\n",
    "            mat = np.load(img)\n",
    "            data.append(mat)\n",
    "            labels.append(label)\n",
    "    data = np.array(data).reshape((len(data),64,64,1))\n",
    "    labels = np.array(labels)\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf27de",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "\n",
    "In this section we are loading the datasets into the memory for traning and testing using our previuosly defined function.\n",
    "\n",
    "* x_(train/test): numpy tensor with images\n",
    "* y_(train/test): numpy array labels \n",
    "\n",
    "The dataset we are using is providing only sub set for training and testing, in order to have a validation sub set, we are splitting the test dataset into two subesets with scikit learn.\n",
    "\n",
    "Why validation subset? this is useful when you want to monitor the model in the training process. this allows to see for example if we have over training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset(\"training\",categories_selected)\n",
    "x_test, y_test = load_dataset(\"training\",categories_selected)\n",
    "\n",
    "#creating an aditional validation dataset \n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52e454",
   "metadata": {},
   "source": [
    "# Summary of datasets\n",
    "\n",
    "Lets see some figures about our is distributed the subsets for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "ax1.set_title('Subsets images')\n",
    "ax2.set_title('Training labels')\n",
    "ax3.set_title('Validation labels')\n",
    "ax4.set_title('Test labels')\n",
    "\n",
    "labels = ['training', 'validation', 'test']\n",
    "shapes = [x_train.shape[0],x_valid.shape[0],x_test.shape[0]]\n",
    "ax1.bar(labels,shapes)\n",
    "\n",
    "ax2.bar(categories_selected,[len(y_train)-np.count_nonzero(y_train),np.count_nonzero(y_train)])\n",
    "\n",
    "ax3.bar(categories_selected,[len(y_valid)-np.count_nonzero(y_valid),np.count_nonzero(y_valid)])\n",
    "\n",
    "ax4.bar(categories_selected,[len(y_test)-np.count_nonzero(y_test),np.count_nonzero(y_test)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d65b0",
   "metadata": {},
   "source": [
    "# Defining the metrics for the model.\n",
    "\n",
    "There is a lot of metrics used in statistis to measure the performance of a model, for this exercise we took\n",
    "the most importants and widely used in medicine.\n",
    "\n",
    "1) the accuracy is the most popular for classification<a href=\"#11\">[11]</a> , it is defined as:\n",
    "$$\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "\n",
    "2) Sensitivity measures the proportion of actual positives that are correctly identified as such\n",
    "$$\\text{Sensitivity} = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "3) Specificity measures the proportion of actual negatives that are correctly identified as such \n",
    "$$\\text{Sensitivity} = \\frac{TN}{TN+FP}$$\n",
    "\n",
    "\n",
    "4) Receiver operating characteristics (ROC), are commonly used in medical decision making <a href=\"#12\">[12]</a> \n",
    "let's take a look for a simple explanetion <a src=\"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\">here</a>\n",
    "\n",
    "Where TP = True Positives, TN = True Negatives, FP = False Positives, and FN = False Negatives.\n",
    "\n",
    "\n",
    "\n",
    "The AUC (Area Under the Curve) for ROC and the accuracy are defined by default in tensorflow metrics, sensitivity and specificity aren't, then I defined then in funcitons that will be called in the training by tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_caller():\n",
    "    _tp = tf.keras.metrics.TruePositives()\n",
    "    _fn = tf.keras.metrics.FalseNegatives()\n",
    "    @tf.function\n",
    "    def sensitivity(y_true, y_pred):\n",
    "        tp = _tp(y_true, y_pred)\n",
    "        fn = _fn(y_true, y_pred)\n",
    "        return tp/(tp+fn+K.epsilon())\n",
    "    return sensitivity\n",
    "\n",
    "def specificity_caller():\n",
    "    _tn = tf.keras.metrics.TrueNegatives()\n",
    "    _fp = tf.keras.metrics.FalsePositives()\n",
    "    @tf.function\n",
    "    def specificity(y_true, y_pred):\n",
    "        tn = _tn(y_true, y_pred)\n",
    "        fp = _fp(y_true, y_pred)\n",
    "        return tn/(tn+fp+K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "metrics = [\n",
    "  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "  tf.keras.metrics.AUC(name='auc'), #ROC\n",
    "  sensitivity_caller(),\n",
    "  specificity_caller()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529567f8",
   "metadata": {},
   "source": [
    "# Machine Learning model\n",
    "\n",
    "The next step is to define the ML model using tensorflow, for this we are using at speialized architecture for image processing based convolutional neural networks.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*kkyW7BR5FZJq4_oBTx3OPQ.png\"/>\n",
    "\n",
    "Long history short, the convolutional neural networks is set of layers that allows to apply filters over the images along the multiple layer to ideantify the pattern.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*ulfFYH5HbWpLTIfuebj5mQ.gif\"/>\n",
    "\n",
    "\n",
    "images taken from https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a17ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#hyperparameters\n",
    "sdropout = 0.2\n",
    "dropout = 0.2\n",
    "n_filter = 2\n",
    "img_size=(64,64,1)\n",
    "optimizer_lr = 1e-3\n",
    "dense_neurons = 8\n",
    "\n",
    "\n",
    "model.add(Conv2D(2*n_filter, kernel_size=16, activation=tf.nn.relu, input_shape=img_size))\n",
    "model.add(Conv2D(4*n_filter, kernel_size=8))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=None, padding='valid', data_format=None))\n",
    "\n",
    "model.add(Conv2D(4*n_filter, kernel_size=8))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "\n",
    "model.add(Conv2D(8*n_filter, kernel_size=4))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_neurons, activation=tf.nn.relu))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.compile(optimizer=Adam(optimizer_lr),\n",
    "              loss='binary_crossentropy',metrics = metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b46e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 10\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), \n",
    "                    batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12862361",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "ax1.set_title('Loss Training/Validation')\n",
    "ax2.set_title('Accuracy Training/Validation')\n",
    "ax3.set_title('Sensitivity Training/Validation')\n",
    "ax4.set_title('Specificity Training/Validation')\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "\n",
    "ax3.plot(history.history['sensitivity'])\n",
    "ax3.plot(history.history['val_sensitivity'])\n",
    "\n",
    "ax4.plot(history.history['specificity'])\n",
    "ax4.plot(history.history['val_specificity'])\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('accuracy')\n",
    "\n",
    "ax3.set_xlabel('epoch')\n",
    "ax3.set_ylabel('sensitivity')\n",
    "\n",
    "ax4.set_xlabel('epoch')\n",
    "ax4.set_ylabel('specificity')\n",
    "\n",
    "\n",
    "ax1.legend(['train loss', 'valid loss'], loc='upper left')\n",
    "ax2.legend(['train acc','valid acc'], loc='upper left')\n",
    "ax3.legend(['train sen','valid sen'], loc='upper left')\n",
    "ax4.legend(['train spe','valid spe'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b698960",
   "metadata": {},
   "source": [
    "# Analysis with the testing subset\n",
    "\n",
    "Let's validate the models with the testing subset, for this we are going to **make a predictions** over the test subset, we are going to plot the **confusion matrix**, **calculate ROC, sensitivity** and **specificity**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4472626",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e422a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e81292",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "plot_confusion_matrix(cm           = confusion_matrix(y_test, y_pred), \n",
    "                      normalize    = False,\n",
    "                      target_names = categories_selected,\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94089aa5",
   "metadata": {},
   "source": [
    "# Sensitivity and specificity\n",
    "As defined on https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "* Sensitivity (True Positive rate) measures the proportion of positives that are correctly identified (i.e. the proportion of those who have some condition (affected) who are correctly identified as having the condition).\n",
    "* Specificity (True Negative rate) measures the proportion of negatives that are correctly identified (i.e. the proportion of those who do not have the condition (unaffected) who are correctly identified as not having the condition).\n",
    "\n",
    "\n",
    "**Sensitivity** = TP / (TP + FN) \n",
    "\n",
    "**Specificity** = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Sensitivity = {sensitivity} \")\n",
    "print(f\"Specificity = {specificity} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca47a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "631c4ac8",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "<a id=\"1\">[1] </a> https://www.aans.org/en/Patients/Neurosurgical-Conditions-and-Treatments/Brain-Tumors\n",
    "\n",
    "<a id=\"2\">[2] </a> https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri\n",
    "\n",
    "<a id=\"3\">[3] </a>https://www.mdpi.com/2076-3417/10/6/1999\n",
    "\n",
    "<a id=\"4\">[4] </a>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4879034/\n",
    "\n",
    "<a id=\"5\">[5] </a>https://github.com/ANTsX/ANTs\n",
    "\n",
    "<a id=\"6\">[6] </a>https://scikit-image.org/\n",
    "\n",
    "<a id=\"7\">[7] </a>https://opencv.org/\n",
    "\n",
    "<a id=\"8\">[8] </a>https://www.tensorflow.org/\n",
    "\n",
    "<a id=\"9\">[9] </a>https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "<a id=\"10\">[10] </a>https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "\n",
    "<a id=\"11\">[11] </a>https://developers.google.com/machine-learning/crash-course/classification/accuracy\n",
    "\n",
    "<a id=\"12\">[12] </a> https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe4ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
